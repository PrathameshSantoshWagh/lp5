{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cm0Z1F8Cs30w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "konRLPatt-Wt"
   },
   "outputs": [],
   "source": [
    "# Load the OCR letter recognition dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data'\n",
    "dataset = pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B_SSH7usufDi"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into features and labels\n",
    "X = dataset.iloc[:, 1:].values  #selecting all rows and selecting all columns from index 1\n",
    "y = dataset.iloc[:, 0].values   #selecting all rows and selecting column with index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnEM21ADukUO",
    "outputId": "8235f99d-870e-419a-e100-6dbcb47f41df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "euZWC8oVunJw"
   },
   "outputs": [],
   "source": [
    "# Encode the labels into numeric value\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_gUFiqauqcT",
    "outputId": "24846f6c-bb01-43ef-b389-10cbc4c083e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nrOxV0dFus9y"
   },
   "outputs": [],
   "source": [
    "#splitting dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lyEaW23guw3W"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 15.0\n",
    "X_test = X_test / 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQh-1dkUuy_2",
    "outputId": "cd9da175-fa98-4f7e-e21c-8dab13b27ba4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#we are using sequential model where layers are stacked one after another,\n",
    "#output of previous layer is given to as input to next layer\n",
    "\n",
    "model = Sequential()\n",
    "#1st layer is dense layer which consists on 128 neurons, since it is 1st layer we need to define input_shape of our training data\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(26, activation='softmax'))  #softmax is used to predict multiclass category outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "iuEFA1rQu1-w"
   },
   "outputs": [],
   "source": [
    "#now we will compile the model\n",
    "\n",
    "#sparse_categorical_crossentropy (scce) produces a category index of the most likely matching category.\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgRYTNzju5aH",
    "outputId": "b3a53a99-0257-49f9-8f03-1e5ac9f62006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1150 - loss: 3.0218 - val_accuracy: 0.5238 - val_loss: 1.8111\n",
      "Epoch 2/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.3753 - loss: 1.9698 - val_accuracy: 0.6077 - val_loss: 1.4233\n",
      "Epoch 3/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.4754 - loss: 1.6790 - val_accuracy: 0.6465 - val_loss: 1.2254\n",
      "Epoch 4/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5285 - loss: 1.4995 - val_accuracy: 0.6780 - val_loss: 1.1453\n",
      "Epoch 5/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5564 - loss: 1.4178 - val_accuracy: 0.6950 - val_loss: 1.0464\n",
      "Epoch 6/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5725 - loss: 1.3644 - val_accuracy: 0.7180 - val_loss: 0.9959\n",
      "Epoch 7/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5898 - loss: 1.2943 - val_accuracy: 0.7410 - val_loss: 0.9420\n",
      "Epoch 8/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6077 - loss: 1.2453 - val_accuracy: 0.7358 - val_loss: 0.9245\n",
      "Epoch 9/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6120 - loss: 1.2271 - val_accuracy: 0.7520 - val_loss: 0.8731\n",
      "Epoch 10/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6253 - loss: 1.1897 - val_accuracy: 0.7542 - val_loss: 0.8582\n",
      "Epoch 11/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 1.1908 - val_accuracy: 0.7563 - val_loss: 0.8313\n",
      "Epoch 12/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6331 - loss: 1.1526 - val_accuracy: 0.7688 - val_loss: 0.7969\n",
      "Epoch 13/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6473 - loss: 1.1349 - val_accuracy: 0.7628 - val_loss: 0.7934\n",
      "Epoch 14/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6467 - loss: 1.1048 - val_accuracy: 0.7755 - val_loss: 0.7702\n",
      "Epoch 15/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 1.1182 - val_accuracy: 0.7675 - val_loss: 0.7561\n",
      "Epoch 16/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.6613 - loss: 1.0699 - val_accuracy: 0.7785 - val_loss: 0.7644\n",
      "Epoch 17/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6653 - loss: 1.0571 - val_accuracy: 0.7757 - val_loss: 0.7461\n",
      "Epoch 18/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.6652 - loss: 1.0378 - val_accuracy: 0.7918 - val_loss: 0.7053\n",
      "Epoch 19/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.6704 - loss: 1.0259 - val_accuracy: 0.7947 - val_loss: 0.7018\n",
      "Epoch 20/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.6720 - loss: 1.0338 - val_accuracy: 0.7945 - val_loss: 0.6907\n",
      "Epoch 21/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6804 - loss: 1.0145 - val_accuracy: 0.7952 - val_loss: 0.6905\n",
      "Epoch 22/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6742 - loss: 1.0153 - val_accuracy: 0.7950 - val_loss: 0.6813\n",
      "Epoch 23/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6820 - loss: 1.0008 - val_accuracy: 0.7975 - val_loss: 0.6908\n",
      "Epoch 24/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6830 - loss: 0.9825 - val_accuracy: 0.8045 - val_loss: 0.6451\n",
      "Epoch 25/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6830 - loss: 0.9940 - val_accuracy: 0.8025 - val_loss: 0.6559\n",
      "Epoch 26/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6929 - loss: 0.9574 - val_accuracy: 0.7980 - val_loss: 0.6660\n",
      "Epoch 27/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6981 - loss: 0.9512 - val_accuracy: 0.8048 - val_loss: 0.6409\n",
      "Epoch 28/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6914 - loss: 0.9744 - val_accuracy: 0.8023 - val_loss: 0.6269\n",
      "Epoch 29/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6811 - loss: 0.9850 - val_accuracy: 0.7968 - val_loss: 0.6373\n",
      "Epoch 30/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6923 - loss: 0.9619 - val_accuracy: 0.8115 - val_loss: 0.6316\n",
      "Epoch 31/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.6949 - loss: 0.9765 - val_accuracy: 0.8123 - val_loss: 0.6302\n",
      "Epoch 32/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6968 - loss: 0.9627 - val_accuracy: 0.8177 - val_loss: 0.5949\n",
      "Epoch 33/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7013 - loss: 0.9466 - val_accuracy: 0.8142 - val_loss: 0.6149\n",
      "Epoch 34/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6996 - loss: 0.9584 - val_accuracy: 0.8160 - val_loss: 0.6087\n",
      "Epoch 35/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7077 - loss: 0.9219 - val_accuracy: 0.8117 - val_loss: 0.6050\n",
      "Epoch 36/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.9244 - val_accuracy: 0.8138 - val_loss: 0.5950\n",
      "Epoch 37/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6991 - loss: 0.9414 - val_accuracy: 0.8125 - val_loss: 0.6112\n",
      "Epoch 38/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.7044 - loss: 0.9359 - val_accuracy: 0.8235 - val_loss: 0.5959\n",
      "Epoch 39/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7057 - loss: 0.9304 - val_accuracy: 0.8223 - val_loss: 0.5901\n",
      "Epoch 40/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6990 - loss: 0.9418 - val_accuracy: 0.8142 - val_loss: 0.5843\n",
      "Epoch 41/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.9294 - val_accuracy: 0.8223 - val_loss: 0.5740\n",
      "Epoch 42/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7175 - loss: 0.8956 - val_accuracy: 0.8165 - val_loss: 0.5838\n",
      "Epoch 43/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 0.8919 - val_accuracy: 0.8217 - val_loss: 0.5717\n",
      "Epoch 44/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.9048 - val_accuracy: 0.8282 - val_loss: 0.5691\n",
      "Epoch 45/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.8989 - val_accuracy: 0.8310 - val_loss: 0.5788\n",
      "Epoch 46/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7132 - loss: 0.9037 - val_accuracy: 0.8260 - val_loss: 0.5696\n",
      "Epoch 47/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7098 - loss: 0.9113 - val_accuracy: 0.8267 - val_loss: 0.5811\n",
      "Epoch 48/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7100 - loss: 0.9093 - val_accuracy: 0.8345 - val_loss: 0.5401\n",
      "Epoch 49/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7114 - loss: 0.9066 - val_accuracy: 0.8360 - val_loss: 0.5622\n",
      "Epoch 50/50\n",
      "\u001b[1m1334/1334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7191 - loss: 0.8942 - val_accuracy: 0.8317 - val_loss: 0.5519\n"
     ]
    }
   ],
   "source": [
    "#The batch size is a number of samples processed before the model is updated.\n",
    "#verbose is the choice that how you want to see the output of your Nural Network while it's training.\n",
    "#If you set verbose = 0, It will show nothing\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=12, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvCbH8mDu8Dy",
    "outputId": "7b4ac0d5-ef3e-4bd1-b8d7-756df0de97f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.5585\n",
      "Test accuracy: 0.8317499756813049\n",
      "Test loss: 0.5519418716430664\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kPSmo7lGv7Og",
    "outputId": "10fb0df1-635b-4881-8b1e-a5f362881ae1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('ocr_model.h5')\n",
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-AR8IDpv-fl",
    "outputId": "20ca3243-0602-4453-b258-2d59715b7f2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('ocr_model.h5')\n",
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yeFfMTY7wC_E"
   },
   "outputs": [],
   "source": [
    "sample_records = X_test[:1000]\n",
    "# Select a few records for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0U_xUf7wU6S",
    "outputId": "fd06c439-eea4-4317-9c9e-574b8dad75b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Perform classification\n",
    "predictions = model.predict(sample_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tnSP3x-0wa_U"
   },
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_letters = label_encoder.inverse_transform(predicted_labels)\n",
    "actual_letters = label_encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NxyUwhyoweIY"
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = np.sum(predicted_labels == y[:1000]) / len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c21GZNHGwhvy",
    "outputId": "1374f2f7-2921-4675-f5d6-3844e64c2a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels\tActual Labels\n",
      "D\t\t\tD\n",
      "D\t\t\tD\n",
      "V\t\t\tV\n",
      "B\t\t\tB\n",
      "H\t\t\tH\n",
      "N\t\t\tN\n",
      "R\t\t\tE\n",
      "Q\t\t\tQ\n",
      "X\t\t\tR\n",
      "N\t\t\tN\n",
      "Q\t\t\tQ\n",
      "O\t\t\tO\n",
      "N\t\t\tN\n",
      "D\t\t\tD\n",
      "I\t\t\tI\n",
      "M\t\t\tM\n",
      "U\t\t\tU\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "A\t\t\tA\n",
      "X\t\t\tX\n",
      "A\t\t\tA\n",
      "K\t\t\tK\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "V\t\t\tV\n",
      "Y\t\t\tY\n",
      "J\t\t\tJ\n",
      "D\t\t\tD\n",
      "V\t\t\tV\n",
      "N\t\t\tD\n",
      "V\t\t\tV\n",
      "K\t\t\tK\n",
      "Y\t\t\tF\n",
      "N\t\t\tN\n",
      "I\t\t\tI\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "H\t\t\tH\n",
      "K\t\t\tK\n",
      "J\t\t\tJ\n",
      "O\t\t\tO\n",
      "M\t\t\tM\n",
      "T\t\t\tT\n",
      "B\t\t\tB\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "C\t\t\tC\n",
      "D\t\t\tD\n",
      "X\t\t\tX\n",
      "K\t\t\tC\n",
      "G\t\t\tG\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "N\t\t\tN\n",
      "Y\t\t\tY\n",
      "Z\t\t\tZ\n",
      "K\t\t\tK\n",
      "C\t\t\tC\n",
      "E\t\t\tT\n",
      "M\t\t\tM\n",
      "W\t\t\tV\n",
      "Q\t\t\tG\n",
      "R\t\t\tM\n",
      "D\t\t\tD\n",
      "T\t\t\tT\n",
      "H\t\t\tH\n",
      "P\t\t\tP\n",
      "N\t\t\tN\n",
      "C\t\t\tC\n",
      "O\t\t\tO\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "V\t\t\tV\n",
      "F\t\t\tP\n",
      "V\t\t\tV\n",
      "G\t\t\tG\n",
      "W\t\t\tW\n",
      "O\t\t\tH\n",
      "P\t\t\tP\n",
      "O\t\t\tO\n",
      "I\t\t\tI\n",
      "G\t\t\tG\n",
      "X\t\t\tX\n",
      "Y\t\t\tX\n",
      "Y\t\t\tP\n",
      "W\t\t\tW\n",
      "O\t\t\tQ\n",
      "D\t\t\tD\n",
      "D\t\t\tN\n",
      "Q\t\t\tQ\n",
      "T\t\t\tT\n",
      "T\t\t\tT\n",
      "Y\t\t\tV\n",
      "Y\t\t\tY\n",
      "I\t\t\tT\n",
      "V\t\t\tV\n",
      "J\t\t\tJ\n",
      "M\t\t\tU\n",
      "D\t\t\tD\n",
      "L\t\t\tL\n",
      "M\t\t\tM\n",
      "Y\t\t\tY\n",
      "E\t\t\tE\n",
      "M\t\t\tM\n",
      "A\t\t\tA\n",
      "Y\t\t\tY\n",
      "K\t\t\tK\n",
      "Y\t\t\tY\n",
      "U\t\t\tU\n",
      "U\t\t\tU\n",
      "U\t\t\tU\n",
      "K\t\t\tC\n",
      "Q\t\t\tQ\n",
      "I\t\t\tI\n",
      "A\t\t\tA\n",
      "E\t\t\tE\n",
      "D\t\t\tD\n",
      "T\t\t\tT\n",
      "S\t\t\tP\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "X\t\t\tX\n",
      "G\t\t\tG\n",
      "F\t\t\tF\n",
      "M\t\t\tM\n",
      "S\t\t\tS\n",
      "E\t\t\tE\n",
      "E\t\t\tE\n",
      "K\t\t\tK\n",
      "Z\t\t\tZ\n",
      "K\t\t\tX\n",
      "O\t\t\tO\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "I\t\t\tI\n",
      "R\t\t\tR\n",
      "O\t\t\tO\n",
      "M\t\t\tM\n",
      "J\t\t\tJ\n",
      "F\t\t\tF\n",
      "K\t\t\tK\n",
      "M\t\t\tM\n",
      "N\t\t\tN\n",
      "G\t\t\tT\n",
      "D\t\t\tD\n",
      "H\t\t\tH\n",
      "R\t\t\tR\n",
      "L\t\t\tL\n",
      "Z\t\t\tZ\n",
      "F\t\t\tF\n",
      "V\t\t\tV\n",
      "W\t\t\tW\n",
      "E\t\t\tE\n",
      "T\t\t\tT\n",
      "W\t\t\tW\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "L\t\t\tL\n",
      "F\t\t\tF\n",
      "O\t\t\tO\n",
      "D\t\t\tD\n",
      "K\t\t\tK\n",
      "S\t\t\tI\n",
      "T\t\t\tX\n",
      "P\t\t\tP\n",
      "H\t\t\tH\n",
      "Q\t\t\tZ\n",
      "D\t\t\tH\n",
      "W\t\t\tW\n",
      "T\t\t\tF\n",
      "B\t\t\tB\n",
      "R\t\t\tR\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "S\t\t\tZ\n",
      "N\t\t\tN\n",
      "W\t\t\tW\n",
      "Z\t\t\tZ\n",
      "W\t\t\tW\n",
      "V\t\t\tV\n",
      "B\t\t\tS\n",
      "V\t\t\tY\n",
      "H\t\t\tH\n",
      "O\t\t\tO\n",
      "T\t\t\tY\n",
      "V\t\t\tV\n",
      "B\t\t\tS\n",
      "W\t\t\tW\n",
      "B\t\t\tB\n",
      "P\t\t\tP\n",
      "D\t\t\tD\n",
      "Z\t\t\tZ\n",
      "O\t\t\tO\n",
      "X\t\t\tX\n",
      "F\t\t\tP\n",
      "B\t\t\tB\n",
      "P\t\t\tS\n",
      "T\t\t\tT\n",
      "X\t\t\tX\n",
      "J\t\t\tJ\n",
      "B\t\t\tB\n",
      "Y\t\t\tY\n",
      "S\t\t\tI\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "E\t\t\tE\n",
      "K\t\t\tH\n",
      "Q\t\t\tQ\n",
      "F\t\t\tI\n",
      "A\t\t\tA\n",
      "H\t\t\tH\n",
      "P\t\t\tP\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "K\t\t\tK\n",
      "P\t\t\tP\n",
      "N\t\t\tM\n",
      "C\t\t\tC\n",
      "X\t\t\tY\n",
      "J\t\t\tJ\n",
      "W\t\t\tW\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "J\t\t\tJ\n",
      "O\t\t\tO\n",
      "T\t\t\tH\n",
      "P\t\t\tP\n",
      "L\t\t\tL\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "C\t\t\tC\n",
      "C\t\t\tC\n",
      "C\t\t\tC\n",
      "O\t\t\tO\n",
      "J\t\t\tJ\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "A\t\t\tA\n",
      "R\t\t\tR\n",
      "Z\t\t\tZ\n",
      "J\t\t\tJ\n",
      "I\t\t\tI\n",
      "G\t\t\tG\n",
      "G\t\t\tG\n",
      "I\t\t\tI\n",
      "K\t\t\tK\n",
      "G\t\t\tM\n",
      "R\t\t\tR\n",
      "T\t\t\tT\n",
      "D\t\t\tD\n",
      "E\t\t\tE\n",
      "D\t\t\tD\n",
      "L\t\t\tL\n",
      "W\t\t\tW\n",
      "G\t\t\tP\n",
      "L\t\t\tL\n",
      "U\t\t\tU\n",
      "O\t\t\tO\n",
      "T\t\t\tT\n",
      "A\t\t\tA\n",
      "V\t\t\tV\n",
      "D\t\t\tD\n",
      "U\t\t\tU\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "G\t\t\tG\n",
      "C\t\t\tC\n",
      "D\t\t\tF\n",
      "Z\t\t\tZ\n",
      "W\t\t\tW\n",
      "T\t\t\tT\n",
      "V\t\t\tV\n",
      "T\t\t\tT\n",
      "P\t\t\tP\n",
      "M\t\t\tM\n",
      "S\t\t\tS\n",
      "U\t\t\tU\n",
      "H\t\t\tF\n",
      "Q\t\t\tQ\n",
      "B\t\t\tB\n",
      "G\t\t\tG\n",
      "K\t\t\tK\n",
      "L\t\t\tL\n",
      "F\t\t\tF\n",
      "E\t\t\tE\n",
      "R\t\t\tR\n",
      "P\t\t\tP\n",
      "R\t\t\tR\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "Y\t\t\tY\n",
      "Y\t\t\tY\n",
      "B\t\t\tB\n",
      "C\t\t\tC\n",
      "T\t\t\tT\n",
      "M\t\t\tM\n",
      "M\t\t\tM\n",
      "O\t\t\tN\n",
      "B\t\t\tB\n",
      "R\t\t\tR\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "D\t\t\tD\n",
      "R\t\t\tR\n",
      "I\t\t\tI\n",
      "Y\t\t\tY\n",
      "F\t\t\tP\n",
      "M\t\t\tM\n",
      "A\t\t\tA\n",
      "B\t\t\tB\n",
      "M\t\t\tM\n",
      "R\t\t\tF\n",
      "O\t\t\tG\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "O\t\t\tO\n",
      "Q\t\t\tQ\n",
      "P\t\t\tP\n",
      "B\t\t\tG\n",
      "N\t\t\tN\n",
      "O\t\t\tO\n",
      "T\t\t\tT\n",
      "G\t\t\tG\n",
      "S\t\t\tS\n",
      "V\t\t\tV\n",
      "A\t\t\tZ\n",
      "A\t\t\tA\n",
      "D\t\t\tP\n",
      "J\t\t\tJ\n",
      "O\t\t\tO\n",
      "N\t\t\tN\n",
      "S\t\t\tQ\n",
      "K\t\t\tK\n",
      "X\t\t\tX\n",
      "S\t\t\tE\n",
      "F\t\t\tP\n",
      "J\t\t\tJ\n",
      "N\t\t\tN\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "V\t\t\tV\n",
      "Q\t\t\tQ\n",
      "Y\t\t\tH\n",
      "A\t\t\tA\n",
      "T\t\t\tT\n",
      "S\t\t\tS\n",
      "W\t\t\tW\n",
      "M\t\t\tM\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "B\t\t\tU\n",
      "S\t\t\tZ\n",
      "R\t\t\tR\n",
      "B\t\t\tB\n",
      "A\t\t\tA\n",
      "Y\t\t\tY\n",
      "F\t\t\tF\n",
      "F\t\t\tF\n",
      "D\t\t\tD\n",
      "A\t\t\tA\n",
      "N\t\t\tN\n",
      "A\t\t\tA\n",
      "N\t\t\tH\n",
      "Q\t\t\tQ\n",
      "P\t\t\tP\n",
      "Z\t\t\tZ\n",
      "R\t\t\tR\n",
      "D\t\t\tD\n",
      "W\t\t\tW\n",
      "O\t\t\tO\n",
      "Q\t\t\tQ\n",
      "K\t\t\tK\n",
      "N\t\t\tN\n",
      "W\t\t\tW\n",
      "P\t\t\tP\n",
      "W\t\t\tW\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "S\t\t\tS\n",
      "I\t\t\tJ\n",
      "E\t\t\tE\n",
      "S\t\t\tS\n",
      "V\t\t\tV\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "V\t\t\tV\n",
      "G\t\t\tT\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "Z\t\t\tZ\n",
      "D\t\t\tD\n",
      "F\t\t\tF\n",
      "P\t\t\tP\n",
      "R\t\t\tR\n",
      "P\t\t\tP\n",
      "C\t\t\tC\n",
      "D\t\t\tD\n",
      "J\t\t\tJ\n",
      "G\t\t\tL\n",
      "I\t\t\tI\n",
      "D\t\t\tH\n",
      "X\t\t\tX\n",
      "B\t\t\tD\n",
      "U\t\t\tU\n",
      "G\t\t\tG\n",
      "O\t\t\tO\n",
      "K\t\t\tK\n",
      "K\t\t\tK\n",
      "K\t\t\tK\n",
      "P\t\t\tP\n",
      "P\t\t\tP\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "F\t\t\tF\n",
      "B\t\t\tB\n",
      "Y\t\t\tY\n",
      "V\t\t\tY\n",
      "I\t\t\tI\n",
      "H\t\t\tH\n",
      "E\t\t\tE\n",
      "S\t\t\tS\n",
      "Y\t\t\tY\n",
      "S\t\t\tS\n",
      "T\t\t\tT\n",
      "Q\t\t\tQ\n",
      "L\t\t\tL\n",
      "R\t\t\tM\n",
      "I\t\t\tI\n",
      "Z\t\t\tZ\n",
      "F\t\t\tF\n",
      "A\t\t\tA\n",
      "J\t\t\tJ\n",
      "B\t\t\tV\n",
      "G\t\t\tG\n",
      "U\t\t\tU\n",
      "Z\t\t\tZ\n",
      "H\t\t\tH\n",
      "O\t\t\tO\n",
      "D\t\t\tN\n",
      "S\t\t\tJ\n",
      "U\t\t\tT\n",
      "O\t\t\tO\n",
      "H\t\t\tH\n",
      "Q\t\t\tV\n",
      "F\t\t\tF\n",
      "L\t\t\tL\n",
      "W\t\t\tW\n",
      "M\t\t\tM\n",
      "T\t\t\tY\n",
      "J\t\t\tJ\n",
      "P\t\t\tP\n",
      "W\t\t\tW\n",
      "E\t\t\tE\n",
      "A\t\t\tA\n",
      "B\t\t\tB\n",
      "W\t\t\tN\n",
      "O\t\t\tO\n",
      "Y\t\t\tQ\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "A\t\t\tA\n",
      "A\t\t\tA\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "E\t\t\tE\n",
      "R\t\t\tH\n",
      "N\t\t\tN\n",
      "E\t\t\tE\n",
      "A\t\t\tA\n",
      "R\t\t\tR\n",
      "G\t\t\tC\n",
      "Z\t\t\tZ\n",
      "Q\t\t\tQ\n",
      "V\t\t\tV\n",
      "O\t\t\tO\n",
      "F\t\t\tT\n",
      "K\t\t\tK\n",
      "M\t\t\tM\n",
      "R\t\t\tR\n",
      "Y\t\t\tY\n",
      "X\t\t\tX\n",
      "X\t\t\tX\n",
      "J\t\t\tJ\n",
      "X\t\t\tX\n",
      "Q\t\t\tQ\n",
      "T\t\t\tT\n",
      "S\t\t\tS\n",
      "A\t\t\tA\n",
      "X\t\t\tX\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "N\t\t\tN\n",
      "B\t\t\tS\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "A\t\t\tA\n",
      "S\t\t\tI\n",
      "T\t\t\tT\n",
      "O\t\t\tX\n",
      "X\t\t\tX\n",
      "C\t\t\tC\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "G\t\t\tG\n",
      "R\t\t\tW\n",
      "D\t\t\tD\n",
      "K\t\t\tK\n",
      "U\t\t\tU\n",
      "S\t\t\tS\n",
      "W\t\t\tO\n",
      "Z\t\t\tZ\n",
      "S\t\t\tL\n",
      "N\t\t\tN\n",
      "R\t\t\tR\n",
      "V\t\t\tV\n",
      "A\t\t\tA\n",
      "K\t\t\tL\n",
      "B\t\t\tD\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "B\t\t\tO\n",
      "K\t\t\tC\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "L\t\t\tL\n",
      "Q\t\t\tQ\n",
      "K\t\t\tK\n",
      "J\t\t\tJ\n",
      "E\t\t\tE\n",
      "B\t\t\tB\n",
      "P\t\t\tP\n",
      "J\t\t\tJ\n",
      "R\t\t\tR\n",
      "X\t\t\tX\n",
      "N\t\t\tN\n",
      "A\t\t\tA\n",
      "G\t\t\tG\n",
      "C\t\t\tC\n",
      "H\t\t\tT\n",
      "L\t\t\tL\n",
      "S\t\t\tS\n",
      "A\t\t\tA\n",
      "N\t\t\tN\n",
      "R\t\t\tK\n",
      "V\t\t\tV\n",
      "B\t\t\tG\n",
      "A\t\t\tA\n",
      "D\t\t\tD\n",
      "H\t\t\tH\n",
      "Y\t\t\tY\n",
      "Z\t\t\tZ\n",
      "Q\t\t\tQ\n",
      "C\t\t\tC\n",
      "U\t\t\tU\n",
      "Q\t\t\tQ\n",
      "Z\t\t\tZ\n",
      "M\t\t\tM\n",
      "D\t\t\tD\n",
      "B\t\t\tB\n",
      "L\t\t\tL\n",
      "B\t\t\tR\n",
      "Q\t\t\tQ\n",
      "D\t\t\tD\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "Q\t\t\tQ\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "S\t\t\tZ\n",
      "B\t\t\tB\n",
      "U\t\t\tU\n",
      "N\t\t\tN\n",
      "K\t\t\tK\n",
      "Q\t\t\tP\n",
      "A\t\t\tA\n",
      "U\t\t\tU\n",
      "P\t\t\tF\n",
      "T\t\t\tT\n",
      "X\t\t\tX\n",
      "L\t\t\tL\n",
      "U\t\t\tU\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "B\t\t\tR\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "Q\t\t\tE\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "Q\t\t\tP\n",
      "P\t\t\tP\n",
      "M\t\t\tM\n",
      "N\t\t\tN\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "R\t\t\tK\n",
      "O\t\t\tO\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "I\t\t\tC\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "R\t\t\tR\n",
      "F\t\t\tI\n",
      "Y\t\t\tY\n",
      "O\t\t\tS\n",
      "V\t\t\tV\n",
      "R\t\t\tR\n",
      "C\t\t\tC\n",
      "Q\t\t\tQ\n",
      "C\t\t\tC\n",
      "Z\t\t\tJ\n",
      "Y\t\t\tY\n",
      "S\t\t\tS\n",
      "K\t\t\tK\n",
      "G\t\t\tL\n",
      "X\t\t\tX\n",
      "T\t\t\tT\n",
      "I\t\t\tI\n",
      "D\t\t\tF\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "O\t\t\tD\n",
      "K\t\t\tK\n",
      "A\t\t\tA\n",
      "Z\t\t\tZ\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "G\t\t\tG\n",
      "W\t\t\tW\n",
      "W\t\t\tW\n",
      "Z\t\t\tZ\n",
      "W\t\t\tW\n",
      "T\t\t\tT\n",
      "O\t\t\tO\n",
      "H\t\t\tR\n",
      "T\t\t\tT\n",
      "N\t\t\tN\n",
      "L\t\t\tS\n",
      "Q\t\t\tQ\n",
      "J\t\t\tJ\n",
      "Q\t\t\tQ\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "A\t\t\tA\n",
      "N\t\t\tN\n",
      "Z\t\t\tZ\n",
      "D\t\t\tD\n",
      "T\t\t\tT\n",
      "I\t\t\tI\n",
      "U\t\t\tU\n",
      "A\t\t\tA\n",
      "O\t\t\tN\n",
      "O\t\t\tG\n",
      "O\t\t\tP\n",
      "L\t\t\tL\n",
      "T\t\t\tF\n",
      "R\t\t\tR\n",
      "C\t\t\tC\n",
      "P\t\t\tP\n",
      "Y\t\t\tY\n",
      "Y\t\t\tY\n",
      "T\t\t\tT\n",
      "A\t\t\tA\n",
      "S\t\t\tY\n",
      "T\t\t\tT\n",
      "Q\t\t\tE\n",
      "T\t\t\tT\n",
      "O\t\t\tO\n",
      "S\t\t\tS\n",
      "N\t\t\tN\n",
      "O\t\t\tO\n",
      "I\t\t\tI\n",
      "O\t\t\tO\n",
      "U\t\t\tU\n",
      "N\t\t\tN\n",
      "Z\t\t\tZ\n",
      "J\t\t\tJ\n",
      "C\t\t\tC\n",
      "N\t\t\tH\n",
      "S\t\t\tS\n",
      "G\t\t\tL\n",
      "H\t\t\tH\n",
      "E\t\t\tC\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "B\t\t\tB\n",
      "W\t\t\tO\n",
      "I\t\t\tI\n",
      "K\t\t\tK\n",
      "O\t\t\tO\n",
      "O\t\t\tR\n",
      "E\t\t\tE\n",
      "L\t\t\tL\n",
      "M\t\t\tM\n",
      "L\t\t\tL\n",
      "X\t\t\tT\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "W\t\t\tW\n",
      "G\t\t\tF\n",
      "D\t\t\tD\n",
      "N\t\t\tN\n",
      "V\t\t\tV\n",
      "M\t\t\tM\n",
      "I\t\t\tI\n",
      "X\t\t\tK\n",
      "L\t\t\tL\n",
      "Y\t\t\tY\n",
      "Q\t\t\tQ\n",
      "F\t\t\tF\n",
      "U\t\t\tU\n",
      "J\t\t\tJ\n",
      "V\t\t\tV\n",
      "M\t\t\tM\n",
      "P\t\t\tP\n",
      "W\t\t\tW\n",
      "L\t\t\tL\n",
      "A\t\t\tA\n",
      "L\t\t\tL\n",
      "B\t\t\tB\n",
      "Y\t\t\tY\n",
      "I\t\t\tI\n",
      "D\t\t\tD\n",
      "R\t\t\tR\n",
      "T\t\t\tT\n",
      "Q\t\t\tQ\n",
      "B\t\t\tB\n",
      "O\t\t\tU\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "I\t\t\tI\n",
      "U\t\t\tU\n",
      "U\t\t\tU\n",
      "X\t\t\tK\n",
      "S\t\t\tJ\n",
      "I\t\t\tI\n",
      "W\t\t\tW\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "A\t\t\tA\n",
      "Z\t\t\tZ\n",
      "P\t\t\tP\n",
      "V\t\t\tV\n",
      "O\t\t\tG\n",
      "B\t\t\tB\n",
      "G\t\t\tG\n",
      "O\t\t\tO\n",
      "V\t\t\tV\n",
      "D\t\t\tD\n",
      "Z\t\t\tZ\n",
      "Y\t\t\tY\n",
      "P\t\t\tP\n",
      "Q\t\t\tQ\n",
      "A\t\t\tA\n",
      "E\t\t\tE\n",
      "W\t\t\tW\n",
      "D\t\t\tD\n",
      "J\t\t\tJ\n",
      "I\t\t\tI\n",
      "J\t\t\tJ\n",
      "X\t\t\tX\n",
      "B\t\t\tS\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "X\t\t\tT\n",
      "U\t\t\tU\n",
      "K\t\t\tK\n",
      "G\t\t\tG\n",
      "I\t\t\tI\n",
      "N\t\t\tN\n",
      "S\t\t\tI\n",
      "W\t\t\tW\n",
      "I\t\t\tI\n",
      "I\t\t\tI\n",
      "P\t\t\tP\n",
      "B\t\t\tB\n",
      "O\t\t\tO\n",
      "H\t\t\tH\n",
      "F\t\t\tD\n",
      "O\t\t\tO\n",
      "N\t\t\tN\n",
      "Z\t\t\tS\n",
      "D\t\t\tD\n",
      "B\t\t\tS\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "W\t\t\tN\n",
      "Y\t\t\tY\n",
      "Y\t\t\tX\n",
      "Q\t\t\tQ\n",
      "N\t\t\tM\n",
      "R\t\t\tR\n",
      "G\t\t\tG\n",
      "Q\t\t\tG\n",
      "A\t\t\tA\n",
      "B\t\t\tK\n",
      "U\t\t\tU\n",
      "U\t\t\tO\n",
      "B\t\t\tP\n",
      "C\t\t\tC\n",
      "V\t\t\tV\n",
      "D\t\t\tD\n",
      "B\t\t\tB\n",
      "A\t\t\tA\n",
      "G\t\t\tE\n",
      "D\t\t\tR\n",
      "T\t\t\tT\n",
      "I\t\t\tI\n",
      "S\t\t\tZ\n",
      "N\t\t\tN\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "C\t\t\tC\n",
      "G\t\t\tG\n",
      "J\t\t\tJ\n",
      "E\t\t\tE\n",
      "N\t\t\tN\n",
      "J\t\t\tJ\n",
      "Q\t\t\tH\n",
      "D\t\t\tP\n",
      "O\t\t\tO\n",
      "O\t\t\tO\n",
      "B\t\t\tB\n",
      "X\t\t\tX\n",
      "B\t\t\tD\n",
      "S\t\t\tS\n",
      "O\t\t\tO\n",
      "O\t\t\tO\n",
      "G\t\t\tG\n",
      "B\t\t\tB\n",
      "R\t\t\tH\n",
      "C\t\t\tC\n",
      "A\t\t\tA\n",
      "W\t\t\tW\n",
      "P\t\t\tP\n",
      "I\t\t\tI\n",
      "N\t\t\tN\n",
      "M\t\t\tM\n",
      "G\t\t\tG\n",
      "N\t\t\tN\n",
      "A\t\t\tA\n",
      "Y\t\t\tH\n",
      "U\t\t\tK\n",
      "N\t\t\tN\n",
      "M\t\t\tM\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "S\t\t\tS\n",
      "E\t\t\tE\n",
      "U\t\t\tT\n",
      "J\t\t\tJ\n",
      "H\t\t\tH\n",
      "N\t\t\tN\n",
      "K\t\t\tK\n",
      "W\t\t\tW\n",
      "W\t\t\tW\n",
      "U\t\t\tU\n",
      "S\t\t\tL\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "Z\t\t\tZ\n",
      "G\t\t\tG\n",
      "T\t\t\tT\n",
      "J\t\t\tJ\n",
      "V\t\t\tV\n",
      "W\t\t\tW\n",
      "L\t\t\tL\n",
      "M\t\t\tM\n",
      "U\t\t\tU\n",
      "W\t\t\tW\n",
      "Q\t\t\tG\n",
      "A\t\t\tA\n",
      "T\t\t\tT\n",
      "J\t\t\tJ\n",
      "C\t\t\tC\n",
      "G\t\t\tG\n",
      "D\t\t\tD\n",
      "T\t\t\tY\n",
      "Y\t\t\tY\n",
      "X\t\t\tX\n",
      "N\t\t\tN\n",
      "Y\t\t\tY\n",
      "Z\t\t\tS\n",
      "K\t\t\tK\n",
      "U\t\t\tU\n",
      "W\t\t\tW\n",
      "R\t\t\tR\n",
      "B\t\t\tB\n",
      "T\t\t\tT\n",
      "R\t\t\tR\n",
      "H\t\t\tH\n",
      "R\t\t\tR\n",
      "M\t\t\tM\n",
      "O\t\t\tO\n",
      "W\t\t\tW\n",
      "X\t\t\tX\n",
      "R\t\t\tR\n",
      "X\t\t\tX\n",
      "N\t\t\tN\n",
      "N\t\t\tH\n",
      "C\t\t\tC\n",
      "E\t\t\tC\n",
      "J\t\t\tJ\n",
      "V\t\t\tV\n",
      "V\t\t\tV\n",
      "I\t\t\tI\n",
      "R\t\t\tR\n",
      "W\t\t\tW\n",
      "O\t\t\tH\n",
      "N\t\t\tN\n",
      "E\t\t\tE\n",
      "U\t\t\tU\n",
      "M\t\t\tM\n",
      "A\t\t\tA\n",
      "B\t\t\tB\n",
      "E\t\t\tE\n",
      "K\t\t\tK\n",
      "T\t\t\tT\n",
      "F\t\t\tF\n",
      "Y\t\t\tY\n",
      "D\t\t\tT\n",
      "H\t\t\tH\n",
      "W\t\t\tW\n",
      "W\t\t\tW\n",
      "O\t\t\tO\n",
      "Q\t\t\tG\n",
      "W\t\t\tW\n",
      "L\t\t\tL\n",
      "Q\t\t\tQ\n",
      "R\t\t\tR\n",
      "U\t\t\tK\n",
      "D\t\t\tD\n",
      "P\t\t\tP\n",
      "T\t\t\tT\n",
      "B\t\t\tB\n",
      "B\t\t\tL\n",
      "V\t\t\tV\n",
      "Q\t\t\tQ\n",
      "G\t\t\tG\n",
      "B\t\t\tS\n",
      "G\t\t\tW\n",
      "V\t\t\tV\n",
      "L\t\t\tL\n",
      "D\t\t\tD\n",
      "R\t\t\tR\n",
      "L\t\t\tL\n",
      "C\t\t\tC\n",
      "N\t\t\tN\n",
      "V\t\t\tV\n",
      "I\t\t\tI\n",
      "P\t\t\tP\n",
      "K\t\t\tC\n",
      "F\t\t\tF\n",
      "W\t\t\tW\n",
      "A\t\t\tA\n",
      "P\t\t\tP\n",
      "F\t\t\tT\n",
      "H\t\t\tH\n",
      "B\t\t\tB\n",
      "K\t\t\tK\n",
      "I\t\t\tI\n",
      "W\t\t\tW\n",
      "D\t\t\tR\n",
      "J\t\t\tJ\n",
      "E\t\t\tR\n",
      "K\t\t\tK\n",
      "A\t\t\tA\n",
      "Q\t\t\tQ\n",
      "Q\t\t\tQ\n",
      "A\t\t\tA\n",
      "M\t\t\tM\n",
      "V\t\t\tV\n",
      "U\t\t\tU\n",
      "G\t\t\tG\n",
      "O\t\t\tO\n",
      "U\t\t\tU\n",
      "D\t\t\tH\n",
      "V\t\t\tV\n",
      "G\t\t\tG\n",
      "Q\t\t\tQ\n",
      "I\t\t\tI\n",
      "T\t\t\tT\n",
      "G\t\t\tG\n",
      "F\t\t\tI\n"
     ]
    }
   ],
   "source": [
    "# Print the predicted labels and corresponding actual labels\n",
    "print(\"Predicted Labels\\tActual Labels\")\n",
    "for i in range(len(predicted_letters)):\n",
    "    print(f\"{predicted_letters[i]}\\t\\t\\t{actual_letters[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zV3e_e8Hwk5A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
